{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from einops import rearrange, reduce, repeat\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "import numpy as np\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import plotly.express as px\n",
    "\n",
    "from model_wrappers import HFModelWrapper\n",
    "from elk import ELK\n",
    "from dataset import Prompts\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## getting ccs to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/ubuntu/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac8eaa02f6c74c058c46abe50da5842c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1054 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 50/50 [00:00<00:00, 640.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"imdb\"\n",
    "prompts = Prompts(dataset_name = dataset_name, N = 50, max_len = 512, random = False)\n",
    "\n",
    "train_indices, test_indices = prompts.gen_train_test_indices(set_instance_vars = True, train_ratio = 0.5, test_ratio = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.85it/s]\n",
      "100%|██████████| 50/50 [00:02<00:00, 18.32it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'activations/t5-3b/imdb_x_plus_activations_2022-12-21.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m elk \u001b[39m=\u001b[39m ELK(\u001b[39m\"\u001b[39m\u001b[39mt5-3b\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m x_plus_acts, x_minus_acts \u001b[39m=\u001b[39m elk\u001b[39m.\u001b[39;49mgen_hidden_states(prompts\u001b[39m.\u001b[39;49mdataset[\u001b[39m'\u001b[39;49m\u001b[39mx_plus\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), \n\u001b[1;32m      4\u001b[0m                                         prompts\u001b[39m.\u001b[39;49mdataset[\u001b[39m'\u001b[39;49m\u001b[39mx_minus\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mtolist(), \n\u001b[1;32m      5\u001b[0m                                         [elk\u001b[39m.\u001b[39;49mmt\u001b[39m.\u001b[39;49mnum_layers],\n\u001b[1;32m      6\u001b[0m                                         store_acts \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m                                         dataset_name \u001b[39m=\u001b[39;49m dataset_name)\n",
      "File \u001b[0;32m~/CCS_on_truthfulqa/elk.py:62\u001b[0m, in \u001b[0;36mELK.gen_hidden_states\u001b[0;34m(self, yes_examples, no_examples, layers, store_acts, dataset_name)\u001b[0m\n\u001b[1;32m     59\u001b[0m x_plus_acts, x_minus_acts \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmt\u001b[39m.\u001b[39mget_activations_last_idx(yes_examples, layers), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmt\u001b[39m.\u001b[39mget_activations_last_idx(no_examples, layers)\n\u001b[1;32m     61\u001b[0m \u001b[39mif\u001b[39;00m store_acts:\n\u001b[0;32m---> 62\u001b[0m     torch\u001b[39m.\u001b[39;49msave(x_plus_acts, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mactivations/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmt\u001b[39m.\u001b[39;49mmodel_name\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataset_name\u001b[39m}\u001b[39;49;00m\u001b[39m_x_plus_activations_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdate\u001b[39m.\u001b[39;49mtoday()\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     63\u001b[0m     torch\u001b[39m.\u001b[39msave(x_minus_acts, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactivations/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmt\u001b[39m.\u001b[39mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mdataset_name\u001b[39m}\u001b[39;00m\u001b[39m_x_minus_activations_\u001b[39m\u001b[39m{\u001b[39;00mdate\u001b[39m.\u001b[39mtoday()\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m \u001b[39mreturn\u001b[39;00m x_plus_acts, x_minus_acts\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.6/lib/python3.9/site-packages/torch/serialization.py:376\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m\"\"\"save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True)\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \n\u001b[1;32m    342\u001b[0m \u001b[39mSaves an object to a disk file.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    372\u001b[0m \u001b[39m    >>> torch.save(x, buffer)\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    374\u001b[0m _check_dill_version(pickle_module)\n\u001b[0;32m--> 376\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mwb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[1;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    378\u001b[0m         \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.6/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.9.6/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'activations/t5-3b/imdb_x_plus_activations_2022-12-21.pt'"
     ]
    }
   ],
   "source": [
    "elk = ELK(\"t5-3b\")\n",
    "\n",
    "x_plus_acts, x_minus_acts = elk.gen_hidden_states(prompts.dataset['x_plus'].tolist(), \n",
    "                                        prompts.dataset['x_minus'].tolist(), \n",
    "                                        [elk.mt.num_layers],\n",
    "                                        store_acts = False,\n",
    "                                        dataset_name = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# COLINS CODE\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "y = prompts.dataset['label'].tolist()\n",
    "x_plus_acts = x_plus_acts\n",
    "x_minus_acts = x_minus_acts\n",
    "\n",
    "# let's create a simple 50/50 train split (the data is already randomized)\n",
    "n = len(y)\n",
    "neg_hs_train, neg_hs_test = x_plus_acts[:n//2], x_plus_acts[n//2:]\n",
    "pos_hs_train, pos_hs_test = x_minus_acts[:n//2], x_minus_acts[n//2:]\n",
    "y_train, y_test = y[:n//2], y[n//2:]\n",
    "\n",
    "# for simplicity we can just take the difference between positive and negative hidden states\n",
    "# (concatenating also works fine)\n",
    "x_train = neg_hs_train - pos_hs_train\n",
    "x_test = neg_hs_test - pos_hs_test\n",
    "\n",
    "lr = LogisticRegression(class_weight=\"balanced\")\n",
    "lr.fit(x_train, y_train)\n",
    "print(\"Logistic regression accuracy: {}\".format(lr.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009273618925362825\n",
      "CCS imdb Train Score: 0.52\n",
      "CCS imdb Test Score: 0.5161290322580645\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "probe_type = \"CCS\"\n",
    "loss = elk.train_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], probe_type = probe_type)\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "probe_score_train = elk.score_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                            prompts.train['label'].tolist(),\n",
    "                            probe_type = probe_type)\n",
    "\n",
    "probe_score_test = elk.score_probe(x_plus_acts[test_indices], x_minus_acts[test_indices],\n",
    "                            prompts.test['label'].tolist(),\n",
    "                            probe_type = probe_type)\n",
    "\n",
    "print(f\"\"\"{probe_type} {dataset_name} Train Score: {probe_score_train}\\n{probe_type} {dataset_name} Test Score: {probe_score_test}\\n\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe Score: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "# train_indices = [0, 1, 2, 3, 4]\n",
    "# test_indices = [5, 6, 7, 8, 9]\n",
    "\n",
    "elk.train_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                labels = prompts.train['label'].tolist(),\n",
    "                probe_type = \"LR\")\n",
    "\n",
    "probe_score = elk.score_probe(x_plus_acts[test_indices], x_minus_acts[test_indices], \n",
    "                              labels = prompts.test['label'],\n",
    "                              probe_type = \"LR\")\n",
    "\n",
    "# zero_shot_score = elk.zero_shot_score(modifiedtqa['question'].tolist(), \n",
    "                                    #   modifiedtqa['label'].tolist())\n",
    "\n",
    "print(f\"Probe Score: {probe_score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance across Model Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset imdb (/home/ubuntu/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a0b3c0b63e4b6fa4fab4d1cd6dad0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1151 > 1024). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [00:00<00:00, 673.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"imdb\"\n",
    "prompts = Prompts(dataset_name = dataset_name, N = 100, max_len = 512, random = True)\n",
    "\n",
    "train_indices, test_indices = prompts.gen_train_test_indices(set_instance_vars = True, train_ratio = 0.6, test_ratio = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([len(elk.mt.tokenizer(prompts.dataset.iloc[i]['x_plus']).input_ids) for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:00<00:00, 73.67it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [00:01<00:00, 71.72it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 79.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.71672854e-03  4.02482506e-03 -9.44943912e-03  9.40153599e-02\n",
      "  3.66733819e-02 -2.72779688e-02  3.06446198e-02 -3.58712524e-02\n",
      "  2.37806570e-02 -3.95216644e-02 -1.21268183e-02  6.07908107e-02\n",
      "  2.55455542e-02 -2.38106716e-02  3.99518088e-02 -4.67830189e-02\n",
      "  5.96576445e-02 -4.59869057e-02  5.69171458e-02  6.35251701e-02\n",
      "  3.26392353e-02  6.47233874e-02  2.01658644e-02  4.46532592e-02\n",
      " -7.43814185e-02 -3.78017686e-02 -1.97887607e-02  4.14290093e-02\n",
      "  4.43106629e-02 -3.94877434e-01 -1.53967403e-02  3.73045392e-02\n",
      "  1.11579355e-02 -6.36513457e-02  5.75111248e-03  3.60372253e-02\n",
      " -5.95039967e-03 -2.49459986e-02 -4.50531843e-05  3.99346389e-02\n",
      "  1.66725889e-02 -6.37608096e-02  2.58907694e-02  8.36172104e-02\n",
      " -6.44278973e-02  4.01740037e-02  2.66935918e-02 -9.39908437e-03\n",
      " -4.68534641e-02  4.28349562e-02  2.03884840e-02  1.39389215e-02\n",
      "  1.74548174e-03  3.07658110e-02  1.64276194e-02  1.31416768e-02\n",
      "  3.49155534e-03  1.57460403e-02 -2.83670751e-03 -5.36880717e-02\n",
      " -2.51044054e-02 -1.55030847e-01 -3.46282274e-02  3.68693471e-02\n",
      " -9.65993777e-02  1.51782651e-02  1.72248241e-02 -1.86341945e-02\n",
      " -4.07477468e-03 -8.41598585e-02  2.56102514e-02  1.96444485e-02\n",
      "  1.02493307e-02  2.52597500e-02 -3.52841280e-02 -1.55928666e-02\n",
      " -1.76069494e-02 -8.14100131e-02 -8.98385188e-04 -1.30159974e-01\n",
      " -1.09769434e-01  1.02226548e-01  9.22802463e-03 -1.38919987e-02\n",
      "  2.85167564e-02 -8.02741721e-02 -3.04965563e-02  2.85958331e-02\n",
      "  4.16659750e-03  5.61352223e-02 -2.88312510e-02 -1.18866619e-02\n",
      " -2.22282112e-02  2.57825144e-02  7.05613643e-02  1.90600567e-02\n",
      "  3.58493328e-02  5.86884171e-02  1.02111295e-01  1.68653447e-02\n",
      " -1.28255785e-02 -2.07775109e-03 -4.44571413e-02  4.37601395e-02\n",
      " -3.90562601e-02  1.92218293e-02  5.55590503e-02  4.02087010e-02\n",
      "  1.09042741e-01 -2.99820881e-02 -1.17126387e-03  5.08357994e-02\n",
      "  6.26682416e-02  6.09617168e-03  3.18681337e-02 -6.34518787e-02\n",
      "  8.84735200e-04 -6.23299256e-02  1.76453944e-02 -4.11644429e-02\n",
      " -3.45336758e-02 -2.40725111e-02  3.33936401e-02  5.07171499e-04\n",
      " -1.77398380e-02 -6.07938133e-02 -4.76940945e-02  7.77570903e-03\n",
      " -8.17662120e-01 -3.56105193e-02  1.48199145e-02 -3.49581678e-04\n",
      " -4.58621345e-02 -1.47109572e-02 -5.15376031e-02 -3.54836434e-02\n",
      " -3.00815701e-01  4.71943058e-02 -2.06726510e-02 -2.76888870e-02\n",
      " -6.73456537e-03  1.04391491e-02 -7.89031237e-02 -4.62953970e-02\n",
      "  1.28163686e-02  1.09943403e-02 -1.01141375e-03 -1.16039932e-01\n",
      "  1.12053733e-02 -1.13294488e-02  8.48178864e-02 -3.74571532e-02\n",
      " -1.77404396e-02 -1.37610929e-02 -2.55542323e-02 -1.44629907e-02\n",
      "  2.15053484e-02  3.87163982e-02 -3.93142886e-02  1.02865379e-02\n",
      "  8.55832535e-04 -5.33010140e-02 -4.63591777e-02 -1.65572595e-02\n",
      "  7.67348148e-03  6.95097297e-02 -6.97190166e-02  7.09446147e-03\n",
      " -2.19851695e-02  1.57333314e-02  1.07142879e-02  1.48583818e-02\n",
      " -2.97168791e-02 -1.29707148e-02 -1.63930596e-03  4.14335839e-02\n",
      " -1.97136942e-02  1.23561248e-01  1.55973900e-02 -6.46849647e-02\n",
      "  2.64930055e-02 -2.34256741e-02  2.51392107e-02  4.33705412e-02\n",
      " -1.06418529e-03 -4.63702492e-02 -2.81868353e-02  5.21747991e-02\n",
      " -4.98530567e-02 -2.80945636e-02 -2.99828108e-02 -1.46398069e-02\n",
      " -4.31641340e-02  2.28555314e-02  3.15851532e-02  2.08783001e-02\n",
      "  3.86166833e-02 -8.51607174e-02  9.11305919e-02 -1.41396942e-02\n",
      "  5.00490218e-02 -5.19599319e-02 -2.42842399e-02  1.79935187e-01\n",
      " -1.68764833e-02 -2.31821332e-02  4.94932383e-02  3.04031279e-03\n",
      " -2.06644665e-02  2.10243221e-02  2.70907041e-02  8.48086625e-02\n",
      "  2.15215497e-02 -4.24833558e-02  5.79179674e-02  2.00753231e-02\n",
      " -1.10836029e-02 -2.32317150e-02 -5.06318733e-02 -6.10215217e-02\n",
      "  5.11740707e-02  2.72344761e-02  7.11759459e-03 -7.06697479e-02\n",
      "  1.69377178e-02  1.46998763e-02  1.11062778e-02  4.37526889e-02\n",
      " -2.86756679e-02 -6.52751476e-02 -1.17996987e-02  2.73305308e-02\n",
      "  5.04101347e-03  3.77115514e-03  2.59364452e-02  5.08599660e-05\n",
      "  1.18332833e-01  7.09189326e-02 -1.58518851e-02  6.22092709e-02\n",
      "  4.85719182e-03 -3.26982997e-02  9.50857624e-03  4.47600707e-02\n",
      "  3.64991464e-02 -3.14552039e-02  5.99291101e-02 -2.60575544e-02\n",
      " -5.09800501e-02  7.64052272e-02 -9.11776326e-04 -3.90937105e-02\n",
      " -5.75509528e-03 -1.78658981e-02 -1.61259584e-02 -4.85396869e-02\n",
      " -9.20239079e-04 -6.49454523e-05  4.18052124e-03  4.85617928e-02\n",
      " -2.36803025e-01 -7.34484801e-03  3.95924710e-02 -3.93831311e-03\n",
      "  9.36261937e-03  5.81693724e-02  5.34910895e-02 -2.30053067e-02\n",
      "  1.04435056e-01 -6.41987920e-02  2.80563366e-02  1.03912577e-02\n",
      "  7.95858130e-02  8.12231526e-02 -1.25812145e-03 -2.26775169e-01\n",
      " -4.35164198e-02 -7.48361945e-02  3.23587283e-02  2.03858875e-02\n",
      " -5.80500476e-02  1.74406897e-02  4.54770774e-02  9.51145682e-03\n",
      "  8.87734741e-02  3.42587312e-03  3.90589833e-02  1.33103384e-02\n",
      " -6.23983378e-03 -8.95268843e-03  3.39433663e-02  3.43988761e-02\n",
      " -2.13505514e-02  1.60197895e-02  3.59895453e-02  6.11592717e-02\n",
      " -1.35262813e-02  5.40474541e-02  6.15657587e-03  6.09535575e-02\n",
      " -8.14185143e-02  9.94290411e-03 -1.71418432e-02 -5.41353188e-02\n",
      "  5.80238290e-02 -7.18268678e-02 -1.53611740e-03  5.84068336e-02\n",
      " -4.19150805e-03  3.71433012e-02 -5.04400730e-02  4.39851952e-04\n",
      "  1.21747389e-01  6.70297025e-03  2.12650672e-02 -5.95903732e-02\n",
      "  1.03338426e-02  9.24548954e-02 -1.15041910e-02  3.15995328e-02\n",
      "  4.58128471e-03 -2.32953783e-02  1.32834837e-02  5.16418880e-03\n",
      "  6.07454451e-03 -1.01029128e-02  1.46582341e-02  9.65228528e-02\n",
      "  6.36243150e-02  4.03937250e-02  6.90955669e-02 -8.04675976e-04\n",
      "  1.40250241e-02  5.23847006e-02  4.19678502e-02 -7.59003311e-02\n",
      "  3.98328491e-02 -2.44347919e-02 -4.71751690e-02  3.55286866e-01\n",
      "  1.32054929e-02  5.49588725e-02  1.97342001e-02 -3.84468175e-02\n",
      " -7.97668919e-02 -8.30488652e-03  4.44364361e-02  5.80031937e-03\n",
      " -5.17646689e-03 -2.14025564e-03 -5.30455168e-03 -3.23044583e-02\n",
      " -2.33849022e-03  6.22167671e-03  4.47114520e-02  6.03932561e-03\n",
      " -1.72227360e-02  2.32103262e-02 -1.11492099e-02 -8.55455920e-02\n",
      " -3.69256223e-03  3.26189213e-02 -1.65847130e-02  1.48012294e-02\n",
      "  7.99320266e-03  5.93841774e-03  6.73857145e-03 -2.55668089e-02\n",
      "  1.35665352e-03  4.30520400e-02 -1.60810989e-04  2.21993290e-02\n",
      "  4.07261699e-02  5.44302464e-02  5.56692015e-03 -3.62885222e-02\n",
      "  2.96491012e-02 -1.25907334e-02 -1.03098387e-02 -4.65720966e-02\n",
      " -5.01435958e-02 -6.10233247e-02  4.37016003e-02  1.07525978e-02\n",
      " -3.27326432e-02  1.22112995e-02  1.42481942e-02 -1.49549320e-02\n",
      " -1.56171247e-02  4.32008356e-02  2.93504931e-02 -2.39843316e-03\n",
      " -2.99922954e-02 -2.29318235e-02 -9.31917969e-03 -3.80571522e-02\n",
      "  3.48537043e-03  6.01242930e-02  2.83761080e-02 -3.40929092e-03\n",
      "  2.58534998e-02  1.23336753e-02 -2.27917563e-02  1.47750368e-02\n",
      "  4.01630402e-02 -1.00167771e-03 -7.27805449e-03 -1.44729512e-02\n",
      " -3.26573849e-02 -3.12402863e-02  7.73857981e-02  8.30033943e-02\n",
      "  9.03276633e-03 -6.10410199e-02  1.25270542e-02  3.90804708e-02\n",
      "  2.44299844e-02 -6.01106249e-02 -3.29866004e-03  3.15629318e-02\n",
      "  1.11293737e-02  1.43891880e-02 -6.25642911e-02 -1.37909511e-02\n",
      "  1.75258820e-03 -4.40928973e-02  2.12234221e-02  1.47132259e-02\n",
      " -5.13172969e-02 -2.92516034e-03  2.97149774e-02  2.40553170e-02\n",
      "  5.15222251e-02  2.59676576e-01 -8.53979290e-02  4.41902280e-02\n",
      " -3.20862560e-03 -1.60843658e-03 -2.22381223e-02 -3.90039571e-02\n",
      " -1.08643612e-02 -4.19643559e-02 -7.78699443e-02 -4.77804802e-02\n",
      " -4.45590429e-02  3.15705389e-02 -5.62507100e-02  3.01979128e-02\n",
      " -2.62177363e-03 -6.08927347e-02  8.05202052e-02  2.24680100e-02\n",
      " -1.64987724e-02 -2.13056430e-02  5.28060198e-02 -4.87367064e-03\n",
      " -7.05387164e-03  1.70982126e-02  1.53799038e-02  1.29828230e-02\n",
      "  2.77186241e-02 -2.40619071e-02 -1.86892785e-02 -5.37828058e-02\n",
      " -3.63148227e-02 -1.98045541e-02  4.11069915e-02 -5.24119101e-03\n",
      "  6.01751655e-02  3.17916945e-02 -1.62974484e-02 -3.95822674e-02\n",
      "  4.89342026e-02  5.60065061e-02 -2.62667462e-02  1.65688053e-01\n",
      " -3.69181670e-02 -4.58243899e-02 -2.61559449e-02  3.74374501e-02\n",
      "  4.34093140e-02 -3.44008841e-02  9.46489349e-02 -1.67233516e-02\n",
      "  4.51694466e-02 -6.44759983e-02  1.66578814e-02 -2.78649610e-02\n",
      "  6.77541783e-03  1.39412889e-02  1.32742058e-02 -6.41736835e-02\n",
      "  1.30008996e-01  3.76085453e-02 -3.19361724e-02 -1.06064500e-02\n",
      "  9.64558572e-02 -3.52297276e-02 -4.05390970e-02  3.05047426e-02\n",
      " -8.82296339e-02  1.40262116e-02 -6.85755815e-03  4.43408592e-03\n",
      "  2.20561586e-02  1.19578652e-01 -2.57515740e-02  4.80837822e-02\n",
      " -7.75914500e-03  2.97580138e-02  5.87798189e-03 -3.92809659e-02]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:14<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.00256867497228086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 51.99it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 62.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS imdb Train Score: 0.5\n",
      "CCS imdb Test Score: 0.5636363636363637\n",
      "Zero Shot Score: 0.44\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:03<00:01, 20.21it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (542 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.63it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12709308 -0.04529818 -0.10413766 ... -0.01617076 -0.05885235\n",
      " -0.00737287]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.001593934721313417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 15.06it/s]\n",
      "100%|██████████| 100/100 [00:06<00:00, 16.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS imdb Train Score: 0.5166666666666666\n",
      "CCS imdb Test Score: 0.5818181818181818\n",
      "Zero Shot Score: 0.53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# model_names = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"EleutherAI/gpt-j-6B\"]\n",
    "# model_names = [\"gpt2\", \"gpt2-medium\"]\n",
    "# model_names = [\"allenai/unifiedqa-t5-small\", \"allenai/unifiedqa-t5-base\", \"allenai/unifiedqa-t5-large\", \"allenai/unifiedqa-t5-3b\", \"allenai/unifiedqa-t5-11b\"]\n",
    "# model_names = [\"allenai/unifiedqa-t5-small\", \"allenai/unifiedqa-t5-base\", \"allenai/unifiedqa-t5-large\"]\n",
    "model_names = [\"t5-small\", \"t5-3b\"]\n",
    "probe_type = \"CCS\"\n",
    "\n",
    "for model_name in model_names:\n",
    "    elk = ELK(model_name)\n",
    "\n",
    "    x_plus_acts, x_minus_acts = elk.gen_hidden_states(prompts.dataset['x_plus'].tolist(), \n",
    "                                            prompts.dataset['x_minus'].tolist(), \n",
    "                                            [elk.mt.num_layers],\n",
    "                                            store_acts = False,\n",
    "                                            dataset_name = dataset_name)\n",
    "    print(x_plus_acts[0])\n",
    "    \n",
    "    torch.cuda.empty_cache() \n",
    "\n",
    "    loss = elk.train_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], probe_type = probe_type)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    \n",
    "    probe_score_train = elk.score_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                                prompts.train['label'].tolist(),\n",
    "                                probe_type = probe_type)\n",
    "\n",
    "    probe_score_test = elk.score_probe(x_plus_acts[test_indices], x_minus_acts[test_indices],\n",
    "                                prompts.test['label'].tolist(),\n",
    "                                probe_type = probe_type)\n",
    "\n",
    "    zero_shot_score = elk.zero_shot_score(prompts.dataset['text'].tolist(), \n",
    "                                        prompts.dataset['label'],\n",
    "                                        dataset_name)\n",
    "\n",
    "    print(f\"\"\"{probe_type} {dataset_name} Train Score: {probe_score_train}\\n{probe_type} {dataset_name} Test Score: {probe_score_test}\\nZero Shot Score: {zero_shot_score}\\n\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe Score: 0.5636363636363636\n",
      "Probe Score: 0.7636363636363637\n",
      "Probe Score: 0.7636363636363637\n"
     ]
    }
   ],
   "source": [
    "# train_indices = [0, 1, 2, 3, 4]\n",
    "# test_indices = [5, 6, 7, 8, 9]\n",
    "# probe_type = \"CCS\"\n",
    "dataset_name = \"imdb\"\n",
    "# model_name = \"gpt2-medium\"\n",
    "np.random.seed(None)\n",
    "# elk = ELK(\"t5-large\")\n",
    "for model_name in model_names:\n",
    "    # elk = ELK(model_name)\n",
    "    \n",
    "    x_plus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_plus_activations_2022-12-21.pt\")\n",
    "    x_minus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_minus_activations_2022-12-21.pt\")\n",
    "        \n",
    "    elk.train_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                    labels = prompts.train['label'].tolist(),\n",
    "                    probe_type = \"LR\")\n",
    "\n",
    "    probe_score = elk.score_probe(x_plus_acts[test_indices], x_minus_acts[test_indices], \n",
    "                                labels = prompts.test['label'].tolist(),\n",
    "                                probe_type = \"LR\")\n",
    "\n",
    "    # zero_shot_score = elk.zero_shot_score(modifiedtqa['question'].tolist(), \n",
    "                                        #   modifiedtqa['label'].tolist())\n",
    "\n",
    "    print(f\"Probe Score: {probe_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0030268258415162563\n",
      "CCS imdb Train Score: 0.5\n",
      "CCS imdb Test Score: 0.5636363636363637\n",
      "Zero Shot Score: 0.56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "dataset_name = \"imdb\"\n",
    "probe_type = \"CCS\"\n",
    "from probes import CCS\n",
    "\n",
    "\n",
    "ccs = CCS()\n",
    "x_plus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_plus_activations_2022-12-21.pt\")\n",
    "x_minus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_minus_activations_2022-12-21.pt\")\n",
    "\n",
    "loss = ccs.fit(x_plus_acts[train_indices], x_minus_acts[train_indices])\n",
    "\n",
    "print(f\"Loss: {loss}\")\n",
    "\n",
    "probe_score_train = ccs.score(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                            prompts.train['label'].tolist(),\n",
    "                            )\n",
    "\n",
    "probe_score_test = ccs.score(x_plus_acts[test_indices], x_minus_acts[test_indices],\n",
    "                            prompts.test['label'].tolist(),\n",
    ")\n",
    "\n",
    "print(f\"\"\"{probe_type} {dataset_name} Train Score: {probe_score_train}\\n{probe_type} {dataset_name} Test Score: {probe_score_test}\\nZero Shot Score: {zero_shot_score}\\n\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t5-small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0015449990751221776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 62.56it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS imdb Train Score: 0.5833333333333333\n",
      "CCS imdb Test Score: 0.5740740740740741\n",
      "Zero Shot Score: 0.43\n",
      "\n",
      "t5-base\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0008160027209669352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 32.21it/s]\n",
      "100%|██████████| 100/100 [00:02<00:00, 34.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS imdb Train Score: 0.5833333333333333\n",
      "CCS imdb Test Score: 0.5740740740740741\n",
      "Zero Shot Score: 0.44\n",
      "\n",
      "t5-large\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0007618818199262023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:06<00:00, 16.60it/s]\n",
      "100%|██████████| 100/100 [00:05<00:00, 17.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCS imdb Train Score: 0.5833333333333334\n",
      "CCS imdb Test Score: 0.5740740740740741\n",
      "Zero Shot Score: 0.56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_name_to_CCS = {}\n",
    "\n",
    "# model_names = [\"gpt2\", \"gpt2-medium\", \"gpt2-large\", \"gpt2-xl\", \"EleutherAI/gpt-j-6B\"]\n",
    "# model_names = [\"allenai/unifiedqa-t5-small\", \"allenai/unifiedqa-t5-base\", \"allenai/unifiedqa-t5-large\", \"allenai/unifiedqa-t5-3b\", \"allenai/unifiedqa-t5-11b\"]\n",
    "\n",
    "probe_type = \"CCS\"\n",
    "dataset_name = \"imdb\"\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    \n",
    "    # elk = ELK(model_name)\n",
    "\n",
    "    x_plus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_plus_activations_2022-12-21.pt\")\n",
    "    x_minus_acts = torch.load(f\"activations/{model_name}/{dataset_name}_x_minus_activations_2022-12-21.pt\")\n",
    "\n",
    "    loss = elk.train_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], probe_type = probe_type)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    \n",
    "    probe_score_train = elk.score_probe(x_plus_acts[train_indices], x_minus_acts[train_indices], \n",
    "                                prompts.train['label'].tolist(),\n",
    "                                probe_type = probe_type)\n",
    "\n",
    "    probe_score_test = elk.score_probe(x_plus_acts[test_indices], x_minus_acts[test_indices],\n",
    "                                prompts.test['label'].tolist(),\n",
    "                                probe_type = probe_type)\n",
    "\n",
    "    zero_shot_score = elk.zero_shot_score(prompts.dataset['text'].tolist(), \n",
    "                                        prompts.dataset['label'],\n",
    "                                        dataset_name)\n",
    "\n",
    "    print(f\"\"\"{probe_type} {dataset_name} Train Score: {probe_score_train}\\n{probe_type} {dataset_name} Test Score: {probe_score_test}\\nZero Shot Score: {zero_shot_score}\\n\"\"\")\n",
    "    \n",
    "    model_name_to_CCS[model_name] = {\n",
    "                                     \"elk\": elk,\n",
    "                                     \"loss\": loss,\n",
    "                                     \"train_score\": probe_score_train,\n",
    "                                     \"test_score\": probe_score_test,\n",
    "                                     \"zero_shot_score\": zero_shot_score\n",
    "                                     }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_scores = [model_name_to_CCS[model_name]['zero_shot_score'] for model_name in model_names]\n",
    "test_scores = [model_name_to_CCS[model_name]['test_score'] for model_name in model_names]\n",
    "train_scores = [model_name_to_CCS[model_name]['train_score'] for model_name in model_names]\n",
    "\n",
    "scores = pd.DataFrame(np.vstack([zero_shot_scores, test_scores, train_scores]).T, columns = [\"zero_shot_score\", \"test_score\", \"train_score\"],\n",
    "                        index = model_names)\n",
    "\n",
    "px.line(scores, x = model_names, y = [\"zero_shot_score\", \"train_score\", \"test_score\"], title = f\"{probe_type} Performance on {dataset_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"imdb\"\n",
    "prompts = Prompts(dataset_name = dataset_name, N = 100, max_len = 512)\n",
    "\n",
    "train_indices, test_indices = prompts.gen_train_test_indices(set_instance_vars = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"t5-small\", \"t5-base\", \"t5-large\", \"t5-3b\", \"t5-11b\"]\n",
    "model_names = [\"allenai/unifiedqa-t5-small\", \"allenai/unifiedqa-t5-base\", \"allenai/unifiedqa-t5-large\", \"allenai/unifiedqa-t5-3b\", \"allenai/unifiedqa-t5-11b\"]\n",
    "elk = ELK(model_names[0])\n",
    "\n",
    "yes_acts, no_acts = elk.gen_hidden_states(prompts.dataset['x_plus'].tolist(), \n",
    "                                        prompts.dataset['x_minus'].tolist(), \n",
    "                                        [elk.mt.num_layers/ 2],\n",
    "                                        store_acts = False,\n",
    "                                        dataset_name = dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elk.train_probe(yes_acts, no_acts, probe_type = \"CCS\")\n",
    "\n",
    "probe_score = elk.score_probe(yes_acts, no_acts, \n",
    "                              torch.tensor(prompts.dataset['x_plus_true']),\n",
    "                              probe_type = \"CCS\")\n",
    "\n",
    "zero_shot_score = elk.zero_shot_score(prompts.dataset['text'].tolist(), \n",
    "                                      prompts.dataset['label'],\n",
    "                                      dataset_name = \"imdb\")\n",
    "\n",
    "print(f\"Probe Score: {probe_score} \\nZero Shot Score: {zero_shot_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "elk.train_probe(yes_acts, no_acts, \n",
    "                labels = modifiedtqa['label'].tolist(),\n",
    "                probe_type = \"LR\")\n",
    "\n",
    "probe_score = elk.score_probe(yes_acts, no_acts, \n",
    "                              labels = modifiedtqa['label'].tolist(),\n",
    "                              probe_type = \"LR\")\n",
    "\n",
    "# zero_shot_score = elk.zero_shot_score(modifiedtqa['question'].tolist(), \n",
    "                                    #   modifiedtqa['label'].tolist())\n",
    "\n",
    "print(f\"Probe Score: {probe_score} \\nZero Shot Score: {zero_shot_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
